# Decision Tree Classifier

This repository contains an implementation of a Decision Tree Classifier written from scratch in Python. The implementation is minimal and intended to illustrate how decision trees work internally without relying on libraries for the core algorithm.

## Features

- Recursive binary splitting.
- Supports Entropy and Gini impurity.
- Stopping conditions: maximum depth and minimum samples per split.
- Prediction by tree traversal.
- Text-based tree printout.
- Visualizations:
  - 2D decision boundary plot.
  - Confusion matrix heatmap.

## Demo / Example workflow

1. Load the Iris dataset.
2. Train the classifier.
3. Print the tree structure.
4. Evaluate on a held-out test set.
5. Display:
   - Classification report.
   - Confusion matrix.
   - Decision boundary for two selected features.

The example demo is included in `decision_tree.py` under the `if __name__ == "__main__":` block.

## Results (Iris dataset)

- Test accuracy: **0.9667** (96.67%)
- Configuration used in the demo: `max_depth=5`, `min_samples_split=2`

Classification report (demo run):

| Class       | Precision | Recall | F1-Score | Support |
|-------------|-----------|--------|----------|---------|
| setosa      | 1.00      | 1.00   | 1.00     | 10      |
| versicolor  | 1.00      | 0.90   | 0.95     | 10      |
| virginica   | 0.91      | 1.00   | 0.95     | 10      |
| **Accuracy**|           |        | **0.97** | 30      |

Confusion matrix (demo run):

|               | Pred setosa | Pred versicolor | Pred virginica |
|---------------|-------------|-----------------|----------------|
| True setosa   | 10          | 0               | 0              |
| True versicolor | 0         | 9               | 1              |
| True virginica | 0          | 0               | 10             |

Visual outputs generated by the demo:
- 2D decision boundary plot.
- Confusion matrix heatmap.

## Purpose

This project is intended to:
- Show how splits are chosen using information gain or Gini impurity.
- Demonstrate recursion for tree growth.
- Illustrate how predictions are made by traversing nodes.
- Provide simple visual diagnostics.
